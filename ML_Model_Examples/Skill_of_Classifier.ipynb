{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Skill_of_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritampalit/ML4DQM/blob/master/Skill_of_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE49EHPK4zIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using ROC curve, PR curve and Confusion matrix to evaluate the skill of Classifier\n",
        "# PR curve is more effective in case of Imbalanced dataset\n",
        "#Author : Pritam Palit, Shamik Ghosh & Francesco Fiori , 14/06/2020"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvMT6I6BHHN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import json\n",
        "#df= pd.read_csv('Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.csv')\n",
        "df= pd.read_csv('/content/drive/My Drive/Colab Notebooks/Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.csv') # To read CSV in Google Colab\n",
        "df['histo']=df['histo'].apply(literal_eval)\n",
        "\n",
        "df.set_index(['fromrun','fromlumi'], inplace=True, drop=False)\n",
        "df.sort_index(inplace=True)\n",
        "print(df['histo'].shape)\n",
        "print(df.tail())\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwqbcqC86TL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "#from tensorflow import set_random_seed\n",
        "tensorflow.random.set_seed(2)\n",
        "#set_random_seed(2)\n",
        "SEED = 123 #used to help randomly select the data points (For Train-test split)\n",
        "DATA_SPLIT_PCT = 0.2\n",
        "DATA_SPLIT_PCT_VALID = 0.1\n",
        "rcParams['figure.figsize'] = 10, 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF45uVsH846x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add Golden JSON labels to the DF\n",
        "import json\n",
        "\n",
        "def checkLS(run,ls):\n",
        "    isok=False\n",
        "    global jsondata\n",
        "\n",
        "    if str(run) in jsondata.keys():\n",
        "        for i in jsondata[str(run)]:\n",
        "            if (ls>=i[0] and ls <=i[1]):\n",
        "                isok=True\n",
        "                return isok\n",
        "        return   isok\n",
        "\n",
        "#load the golden json file\n",
        "jsondata={}\n",
        "#with open('GoldenJSON17.json') as json_file: # While not in Google Colab\n",
        "with open('/content/drive/My Drive/Colab Notebooks/GoldenJSON17.json') as json_file:\n",
        "    jsondata = json.load(json_file)\n",
        "\n",
        "df['labels']=False #initialize to false\n",
        "\n",
        "for run in df['fromrun'].unique():\n",
        "    for ls in df['fromlumi'][run]:\n",
        "        df['labels'][run][ls]=checkLS(run,ls)\n",
        "\n",
        "# 'type' is just opposite of labels to take Good as 0 and Bad as 1 automatically for the input of ROC & PR curves\n",
        "df['type']=df['labels']\n",
        "df['type']=df['type'].apply(lambda x:0 if x== True else 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLedH8KoP1Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split total dataset into Train , Test and Validation (72:20:8)%\n",
        "df_train, df_test = train_test_split(df, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "df_train, df_valid = train_test_split(df_train, test_size=DATA_SPLIT_PCT_VALID, random_state=SEED)\n",
        "\n",
        "X_train_true = np.stack(df_train['histo'][df_train['labels']==True].values, axis=0)\n",
        "X_train_false = np.stack(df_train['histo'][df_train['labels']==False].values, axis=0)\n",
        "\n",
        "X_valid_true = np.stack(df_valid['histo'][df_valid['labels']==True].values, axis=0)\n",
        "X_valid_false = np.stack(df_valid['histo'][df_valid['labels']==False].values, axis=0)\n",
        "\n",
        "\n",
        "X_test_true = np.stack(df_test['histo'][df_test['labels']==True].values, axis=0)\n",
        "X_test_false = np.stack(df_test['histo'][df_test['labels']==False].values, axis=0)\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "X_train_true_norm=normalize(X_train_true, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
        "X_train_false_norm=normalize(X_train_false, norm='l1', axis=1)\n",
        "\n",
        "X_valid_true_norm=normalize(X_valid_true, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
        "X_valid_false_norm=normalize(X_valid_false, norm='l1', axis=1)\n",
        "\n",
        "X_test_true_norm=normalize(X_test_true, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
        "X_test_false_norm=normalize(X_test_false, norm='l1', axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJklxfxE_He8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the model\n",
        "import math\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "def mseTop10(y_true, y_pred):\n",
        "    top_values, _ = tf.nn.top_k(K.square(y_pred - y_true), k=10, sorted=True)\n",
        "    mean=K.mean(top_values, axis=-1)\n",
        "    return mean\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 500\n",
        "input_dim = X_train_true_norm.shape[1] #num of predictor variables, \n",
        "encoding_dim = 10\n",
        "hidden_dim = 3\n",
        "learning_rate = 1e-3\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\")(input_layer)  \n",
        "decoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n",
        "decoder = Dense(encoding_dim, activation=\"tanh\")(decoder)\n",
        "decoder = Dense(input_dim, activation=\"tanh\")(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3x-HTLdCWaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss=mseTop10,\n",
        "                    optimizer='adam')\n",
        "history = autoencoder.fit(X_train_true_norm, X_train_true_norm,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_valid_true_norm, X_valid_true_norm),\n",
        "                    verbose=1,\n",
        "                    ).history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB5sxIBPFOOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(history)\n",
        "\n",
        "line_styles = [(0, ()), (0, (1, 3)), (0, (3, 2))]\n",
        "\n",
        "color_palette = {\"Indigo\": {\n",
        "                    50: \"#E8EAF6\",\n",
        "                    100: \"#C5CAE9\",\n",
        "                    200: \"#9FA8DA\",\n",
        "                    300: \"#7986CB\",\n",
        "                    400: \"#5C6BC0\",\n",
        "                    500: \"#3F51B5\",\n",
        "                    600: \"#3949AB\",\n",
        "                    700: \"#303F9F\",\n",
        "                    800: \"#283593\",\n",
        "                    900: \"#1A237E\"},\n",
        "                 \"Teal\": {      \n",
        "                    50: \"#E0F2F1\",\n",
        "                    100: \"#B2DFDB\",\n",
        "                    200: \"#80CBC4\",\n",
        "                    300: \"#4DB6AC\",\n",
        "                    400: \"#26A69A\",\n",
        "                    500: \"#009688\",\n",
        "                    600: \"#00897B\",\n",
        "                    700: \"#00796B\",\n",
        "                    800: \"#00695C\",\n",
        "                    900: \"#004D40\"}\n",
        "                }\n",
        "\n",
        "# \"Loss\"\n",
        "plt.figure(1)\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.yscale(\"log\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIckNz1D3QRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from numpy import sqrt\n",
        "from numpy import argmax\n",
        "import seaborn as sns\n",
        "\n",
        "#Details of Reconstruction error for Test dataset\n",
        "# df must have two columns : 'histo' & 'type' as described above\n",
        "# 'true class' of column 'type' will help to classify '1' (Positive) for Anomaly and '0' (Negative) for Good, to draw ROC & P-R curves\n",
        "def Skill_of_Classifier(df) :\n",
        "  X_all = np.stack(df['histo'].values, axis=0)\n",
        "  X_all_norm=normalize(X_all, norm='l1', axis=1)\n",
        "  x_predictions = autoencoder.predict(X_all_norm)\n",
        "  mse=K.eval(mseTop10(X_all_norm, x_predictions))\n",
        "  print(mse)\n",
        "  error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': df['type']})\n",
        "  print(error_df.describe())\n",
        "  \n",
        "  # Plot ROC curve and calculate g-mean to find the best point of ROC curve\n",
        "  fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  # calculate the g-mean for each threshold\n",
        "  gmeans = sqrt(tpr * (1-fpr))\n",
        "  # locate the index of the largest g-mean\n",
        "  ix = argmax(gmeans)\n",
        "  print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
        "  fig = plt.figure(1)\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.plot([0,1],[0,1],'r--')\n",
        "  plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "  plt.xlim([-0.001, 1])\n",
        "  plt.ylim([0, 1.001])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  \n",
        "  # Plot PR curve and calculate f-score to find the best point of ROC curve\n",
        "  precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
        "  auc_PR = auc(recall, precision)\n",
        "  # convert to f score\n",
        "  fscore = (2 * precision * recall) / (precision + recall)\n",
        "  # locate the index of the largest f1 score\n",
        "  ix = argmax(fscore)\n",
        "  print('Best Threshold=%f, F-Score=%.3f' % (th[ix], fscore[ix]))\n",
        "  plt.figure(2)\n",
        "  plt.plot(recall, precision, 'b', label='AUC = %0.4f'% auc_PR)\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
        "  plt.title('Recall vs Precision')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  \n",
        "  # Plot Precision and recall for different threshold values for to get the ideal threshold\n",
        "  plt.figure(3)\n",
        "  plt.plot(th, precision[1:], label=\"Precision\",linewidth=5)\n",
        "  plt.plot(th, recall[1:], label=\"Recall\",linewidth=5)\n",
        "  plt.legend(loc='right')\n",
        "  plt.title('Precision and recall for different threshold values')\n",
        "  plt.xlabel('Threshold')\n",
        "  plt.ylabel('Precision/Recall')\n",
        "\n",
        "  # Confusion Matrix to get the Actual Class vs Predicted Class\n",
        "  threshold = th[ix] # Using threshold of PR curve\n",
        "  LABELS = ['Good', 'Anomaly']\n",
        "  y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
        "  conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
        "  plt.figure(4)\n",
        "  sns.set(font_scale=2)\n",
        "  sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "  plt.title(\"Confusion matrix for Test, th = %f\" % (th[ix]))\n",
        "  plt.ylabel('True class')\n",
        "  plt.xlabel('Predicted class')\n",
        "  plt.show();\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJeXH96mgJ5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Skill_of_Classifier(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}