{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Unnamed: 0  fromrun  fromlumi                  hname  \\\n",
      "fromrun fromlumi                                                         \n",
      "306462  95             67823   306462        95  chargeInner_PXLayer_1   \n",
      "        96             67824   306462        96  chargeInner_PXLayer_1   \n",
      "        97             67825   306462        97  chargeInner_PXLayer_1   \n",
      "        98             67826   306462        98  chargeInner_PXLayer_1   \n",
      "        99             67827   306462        99  chargeInner_PXLayer_1   \n",
      "\n",
      "                  entries     Xmax  Xmin  Xbins  metype  \\\n",
      "fromrun fromlumi                                          \n",
      "306462  95              0  80000.0   0.0    100       3   \n",
      "        96              0  80000.0   0.0    100       3   \n",
      "        97              0  80000.0   0.0    100       3   \n",
      "        98              0  80000.0   0.0    100       3   \n",
      "        99              0  80000.0   0.0    100       3   \n",
      "\n",
      "                                                              histo  \n",
      "fromrun fromlumi                                                     \n",
      "306462  95        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "        96        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "        97        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "        98        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "        99        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "599\n"
     ]
    }
   ],
   "source": [
    "#get the good data\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import json\n",
    "\n",
    "df= pd.read_csv('PixelStudy/ZeroBias_2017UL_DataFrame_ChargeInnerLayer2.txt')#'GOLDEN_Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.csv')\n",
    "\n",
    "df['histo']=df['histo'].apply(literal_eval)\n",
    "df=df.loc[df.entries>0].copy()\n",
    "\n",
    "df.set_index(['fromrun','fromlumi'], inplace=True, drop=False)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(df.tail())\n",
    "print(df.fromrun.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotHist(df,run,nolabels=True,fsave=False,hname=\"chargeInner_PXLayer_2\", mode=1):\n",
    "\n",
    "    Xmax=80000.0\n",
    "    Xmin=0.0\n",
    "    Xbins=100\n",
    "    halfbinwhidth=(Xmax-Xmin)/(2.0*Xbins)      \n",
    "    \n",
    "    x= np.linspace(Xmin+halfbinwhidth,Xmax-halfbinwhidth,Xbins)  \n",
    "    \n",
    "    if (mode==1): plt.xlim(Xmin,Xmax)\n",
    "    \n",
    "    plt.title(hname + \" \" + str(run)+\" (\"+ str((df['fromlumi'][run]).size) + \")\")\n",
    "    \n",
    "    for ls in df['fromlumi'][run]:\n",
    "        ahisto=np.array(df['histo'][run][ls]).astype('float')\n",
    "        \n",
    "        if (mode==1):\n",
    "            if nolabels: plt.step(x, ahisto, where='mid', label=(\" LS \" + str(df.fromlumi[run][ls]) + \" Run \" + str(df.fromrun[run][ls]) ))\n",
    "            else: \n",
    "                if (df['labels'][run][ls]==True): plt.step(x, ahisto, where='mid', c=\"green\",label=(\" LS \" + str(df.fromlumi[run][ls]) + \" Run \" + str(df.fromrun[run][ls]) ))\n",
    "                if (df['labels'][run][ls]==False): plt.step(x, ahisto, where='mid', c=\"red\",label=(\" LS \" + str(df.fromlumi[run][ls]) + \" Run \" + str(df.fromrun[run][ls]) ))\n",
    "    \n",
    "        if (mode==2):\n",
    "            value=np.dot(ahisto,x)/ahisto.sum()\n",
    "            if nolabels: plt.scatter(float(ls),value,color=\"blue\",marker=\".\")\n",
    "            else: \n",
    "                if (df['labels'][run][ls]==True): plt.scatter(float(ls),value,color=\"green\",marker=\".\")\n",
    "                if (df['labels'][run][ls]==False): plt.scatter(float(ls),value,color=\"red\",marker=\".\")\n",
    "    \n",
    "    \n",
    "    if (mode==1):\n",
    "        plt.xlabel(\"Charge electrons\")\n",
    "        plt.ylabel(\"A.U\")\n",
    "        \n",
    "    if (mode==2):\n",
    "        plt.xlabel(\"Lumisection\")\n",
    "        plt.ylabel(\"Histo Average\")\n",
    "    \n",
    "    \n",
    "    if fsave:\n",
    "        fname=\"\"\n",
    "        if (mode==1): fname=hname + \"_\"+ str(run)+\".png\"\n",
    "        if (mode==2): fname=hname + \"_\"+ str(run)+\"_trend.png\"\n",
    "        plt.savefig(fname)\n",
    "        \n",
    "    #if (legend): plt.legend()\n",
    "    plt.show()\n",
    "    #plt.savefig('chargeInner_PXLayer_1_GOOD.png')\n",
    "    \n",
    "PlotHist(df,301998, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Golden JSON labels to the DF\n",
    "import json\n",
    "\n",
    "def checkLS(run,ls):\n",
    "    isok=False\n",
    "    global jsondata\n",
    "    \n",
    "    if str(run) in jsondata.keys():\n",
    "        for i in jsondata[str(run)]:\n",
    "            if (ls>=i[0] and ls <=i[1]):\n",
    "                isok=True\n",
    "                return isok\n",
    "        return isok\n",
    "\n",
    "#load the golden json file\n",
    "jsondata={}\n",
    "with open('GoldenJSON17.json') as json_file:\n",
    "    jsondata = json.load(json_file)\n",
    "\n",
    "df['labels']=False #initialize to false\n",
    "\n",
    "for run in df['fromrun'].unique():\n",
    "    for ls in df['fromlumi'][run]:\n",
    "        df['labels'][run][ls]=checkLS(run,ls)\n",
    "\n",
    "#print(df[df['labels']==True]) #to check against the Golden JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a JSON plot\n",
    "for run in df['fromrun'].unique():\n",
    "    PlotHist(df,run,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use golden lumisections to train the model\n",
    "\n",
    "X_trainS = np.stack(df['histo'][df['labels']==True].values, axis=0) #convert list of array to a stack to feed the model\n",
    "X_testS = np.stack(df['histo'][df['labels']==False].values, axis=0)\n",
    "\n",
    "#print(X_trainS)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_train=normalize(X_trainS, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
    "X_test=normalize(X_testS, norm='l1', axis=1)\n",
    "                      \n",
    "df['origin']=''\n",
    "df['origin'].loc[df['labels']==True]=X_train.tolist()\n",
    "df['origin'].loc[df['labels']==False]=X_test.tolist()\n",
    "print(df.shape)\n",
    "print(df.origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the simple model\n",
    "import math\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def mseTop10(y_true, y_pred):\n",
    "    top_values, _ = tf.nn.top_k(K.square(y_pred - y_true), k=10, sorted=True)\n",
    "    mean=K.mean(top_values, axis=-1)\n",
    "    return mean\n",
    "\n",
    "input_size=len(X_train[0])\n",
    "\n",
    "input_layerA = Input(shape=(input_size, ))\n",
    "\n",
    "encodedA = Dense(20, activation='sigmoid')(input_layerA)\n",
    "encoded1A = Dense(10, activation='tanh')(encodedA)\n",
    "encoded2A = Dense(20, activation='sigmoid')(encoded1A)\n",
    "decoderA = Dense(input_size, activation='sigmoid')(encoded2A)\n",
    "\n",
    "autoencoder= Model(inputs=input_layerA, outputs=decoderA)\n",
    "autoencoder.compile(optimizer='adam', loss=mseTop10)\n",
    "\n",
    "for i, layer in enumerate(autoencoder.layers):\n",
    "             layer.name = 'layer_' + str(i)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = autoencoder.fit(X_train,X_train, epochs=300, batch_size=100, shuffle=True, verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and load model, for some reasons doesn't work on Swan\n",
    "#autoencoder.save(\"Test_AE.h5\")\n",
    "#autoencoder=load_model(\"Test_AE.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_styles = [(0, ()), (0, (1, 3)), (0, (3, 2))]\n",
    "\n",
    "color_palette = {\"Indigo\": {\n",
    "                    50: \"#E8EAF6\",\n",
    "                    100: \"#C5CAE9\",\n",
    "                    200: \"#9FA8DA\",\n",
    "                    300: \"#7986CB\",\n",
    "                    400: \"#5C6BC0\",\n",
    "                    500: \"#3F51B5\",\n",
    "                    600: \"#3949AB\",\n",
    "                    700: \"#303F9F\",\n",
    "                    800: \"#283593\",\n",
    "                    900: \"#1A237E\"},\n",
    "                 \"Teal\": {      \n",
    "                    50: \"#E0F2F1\",\n",
    "                    100: \"#B2DFDB\",\n",
    "                    200: \"#80CBC4\",\n",
    "                    300: \"#4DB6AC\",\n",
    "                    400: \"#26A69A\",\n",
    "                    500: \"#009688\",\n",
    "                    600: \"#00897B\",\n",
    "                    700: \"#00796B\",\n",
    "                    800: \"#00695C\",\n",
    "                    900: \"#004D40\"}\n",
    "                }\n",
    "\n",
    "def plot_loss(data, title):\n",
    "    \"\"\"Plots the training and validation loss\"\"\"\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.plot(data.history['loss'], linestyle=line_styles[0], color=color_palette[\"Indigo\"][900], linewidth=3)\n",
    "    plt.plot(data.history['val_loss'], linestyle=line_styles[2], color=color_palette[\"Teal\"][300], linewidth=3)\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper right\", frameon=False)\n",
    "    #plt.ylim(8258339,8258400)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlim(0,100)\n",
    "    plt.show();\n",
    "\n",
    "plot_loss(history, \"Original model loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add predictions and mse as new columns in the AE\n",
    "predictionTest=autoencoder.predict(X_test)\n",
    "predictionTrain=autoencoder.predict(X_train)\n",
    "\n",
    "mseTest=K.eval(mseTop10(X_test, predictionTest))\n",
    "mseTrain=K.eval(mseTop10(X_train, predictionTrain))\n",
    "\n",
    "df['prediction']=\"\"\n",
    "df['mse']=\"\"\n",
    "\n",
    "df['prediction'].loc[df['labels']==True]=predictionTrain.tolist()\n",
    "df['prediction'].loc[df['labels']==False]=predictionTest.tolist()\n",
    "\n",
    "df['mse'].loc[df['labels']==True]=mseTrain\n",
    "df['mse'].loc[df['labels']==False]=mseTest\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalMSETrend(df,type=1):\n",
    "    \n",
    "    y=[]\n",
    "    \n",
    "    rmax=0\n",
    "    rmin=10\n",
    "    \n",
    "    print(rmax, rmin)\n",
    "    for run in df['fromrun'].unique():\n",
    "        if (type==1): val=(df['mse'][run]).mean()\n",
    "        if (type==2): val=(df['mse2'][run]).mean()\n",
    "        if val > rmax: rmax=val\n",
    "        if val < rmin: rmin =val\n",
    "        y.append(val)\n",
    "    \n",
    "    array=np.array(y)\n",
    "    gmean=array.mean()\n",
    "    size=float(array.size)\n",
    "    gstd=array.std()\n",
    "    print(size)\n",
    "    \n",
    "    fig=plt.figure()\n",
    "    fig.set_size_inches(16, 9)\n",
    "    \n",
    "    plt.hlines(gmean,df['fromrun'].unique().min(), df['fromrun'].unique().max(), color=\"blue\", label=\"Run average: \" + str(gmean))\n",
    "    plt.hlines(gmean+(1.0*gstd), df['fromrun'].unique().min(), df['fromrun'].unique().max(), color=\"red\", label='1 SD (' + str(gstd) + \")\")\n",
    "    plt.hlines(gmean+(3.0*gstd), df['fromrun'].unique().min(), df['fromrun'].unique().max(), color=\"red\", label='3 SD', linestyle=':')\n",
    "    \n",
    "    plt.ylim(rmin*0.9,rmax*1.1)\n",
    "    plt.scatter(df['fromrun'].unique(), y, marker='+', label='Data points')\n",
    "    plt.xlabel(\"Run\")\n",
    "    plt.ylabel(\"average MSE\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalMSETrend(df[df.labels==True]) # mse trend of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalMSETrend(df[(df.labels==False) & (df.entries>0)]) # mse trend of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def CheckPredictions(df_test, run, ls, type=1, save=False):\n",
    "\n",
    "    Xmax=80000.0\n",
    "    Xmin=0.0\n",
    "    Xbins=100\n",
    "    hname=\"chargeInner_PXLayer_1\"\n",
    "    \n",
    "    ahisto=np.array(df_test['origin'][run][ls])\n",
    "    ahisto1=np.empty(ahisto.shape[0])\n",
    "    if type==1: ahisto1=np.array(df_test['prediction'][run][ls])\n",
    "    if type==2: ahisto1=np.array(df_test['prediction2'][run][ls]) \n",
    "        \n",
    "    mse=[]\n",
    "    if type==1:mse=df_test['mse'][run][ls]\n",
    "    if type==2:mse=df_test['mse2'][run][ls]\n",
    "        \n",
    "    msebin=(ahisto-ahisto1)**2\n",
    "    \n",
    "    gs = gridspec.GridSpec(7,1)\n",
    "    \n",
    "    x= np.linspace(Xmin,Xmax,Xbins)\n",
    "    xbin=np.linspace(0,Xbins,Xbins)\n",
    "    fig= plt.figure()\n",
    "    fig.set_size_inches(5,5)\n",
    "    \n",
    "    axs0=plt.subplot(gs[:4, :])\n",
    "    axs1=plt.subplot(gs[5:, :])\n",
    "    \n",
    "    axs0.step(x, ahisto, where='mid', label=(\" Data LS \" + str(df_test.fromlumi[run][ls]) + \" Run \" + str(df_test.fromrun[run][ls]) ))\n",
    "    axs0.step(x, ahisto1, where='mid', label=\" Reco MSE=\" + str(mse))\n",
    "    axs1.step(xbin, msebin, where='mid')\n",
    "    axs0.set(xlabel=\"Charge electrons\",ylabel=\"A.U\")\n",
    "    axs1.set(ylabel=\"MSE\", xlabel=\"bin\")\n",
    "    axs0.legend()\n",
    "    if save: plt.savefig(hname + \"_\" + str(run) + \"_LS\" +str(ls) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in df['fromrun'].unique(): #check few orediction plots, max 2 per run\n",
    "    count=0\n",
    "    for ls in df['fromlumi'][run]: \n",
    "        if df['labels'][run][ls]== False: continue\n",
    "        if (count >2): continue\n",
    "        count=count+1\n",
    "        CheckPredictions(df[df.labels==True], run,ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseHisto(df):\n",
    "    g=np.array(df['mse'][df.labels==True])\n",
    "    w=np.array(df['mse'][(df.labels==False) & (df.entries>0)])\n",
    "    plt.hist(w,bins=100,range=(w.min()*0.8,(w.max()*1.2)), alpha=0.5, color=\"red\", label=\"Test\")\n",
    "    plt.hist(g,bins=100,range=(w.min()*0.8,(w.max()*1.2)), alpha=0.5, color=\"green\", label=\"Train\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "mseHisto(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in df['fromrun'].unique(): #to check few plots based on the histograms produced above\n",
    "    count=0\n",
    "    for ls in df['fromlumi'][run]: \n",
    "        if df['labels'][run][ls]== True: continue\n",
    "        if df['mse'][run][ls]< 0.015: continue\n",
    "        #if (count >2): continue\n",
    "        count=count+1\n",
    "        CheckPredictions(df[df.labels==False], run,ls,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you should add more cells to complete the study, i.e find a good threshold for the mse to separate anomalous histograms from standard ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
